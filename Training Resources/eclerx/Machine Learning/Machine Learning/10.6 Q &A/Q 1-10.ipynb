{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad7e83b9-f604-4579-9946-be212b2b4220",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "1. A machine learning engineer has created a Feature Table new_table using FeatureStore Client fs. When creating the table, they specified a metadata description with keyinformation about the Feature Table. They now want to retrieve that metadata programmatically.Which of the following lines of code will return the metadata description?\n",
    "\n",
    "A. There is no way to return the metadata description programmatically.\n",
    "\n",
    "B. fs.create_training_set(\"new_table\")\n",
    "\n",
    "C. fs.get_table(\"new_table\").description\n",
    "\n",
    "D. fs.get_table(\"new_table\").load_df()\n",
    "\n",
    "E. fs.get_table(\"new_table\")\n",
    "\n",
    "Answer: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59e50fd0-c525-483d-a234-9fae4870f4c3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "2"
    }
   },
   "outputs": [],
   "source": [
    "A data scientist has a Spark DataFrame spark_df. They want to create a new SparkDataFrame that contains only the rows from spark_df where the value in column price isgreater than 0.Which of the following code blocks will accomplish this task?\n",
    "\n",
    "#A. spark_df[spark_df[\"price\"] > 0]\n",
    "B. spark_df.filter(col(\"price\") > 0)\n",
    "#C. SELECT * FROM spark_df WHERE price > 0\n",
    "#D. spark_df.loc[spark_df[\"price\"] > 0,:]\n",
    "#E. spark_df.loc[:,spark_df[\"price\"] > 0\n",
    "\n",
    "Answer: B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3786573c-309e-4911-92d6-2f3479230b6b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "3"
    }
   },
   "outputs": [],
   "source": [
    "A health organization is developing a classification model to determine whether or not a patient currently has a specific type of infection. The organization's leaders want to maximize the number of positive cases identified by the model. Which of the following classification metrics should be used to evaluate the model?\n",
    "\n",
    "#A. RMSE\n",
    "\n",
    "B. Precision\n",
    "\n",
    "C. Area under the residual operating curve\n",
    "\n",
    "#D. Accuracy\n",
    "\n",
    "E. Recall\n",
    "\n",
    "Answer: E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7952b20-222d-401d-b276-db9f4f97a7de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "precision= True Positives / ( TP + FP)\n",
    "\n",
    "recall = True Positives / ( TP + FN)\n",
    "\n",
    "accuracty = TP TN and Total prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef33b647-12cd-42a6-89fb-1ddeb1c4547c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "4"
    }
   },
   "outputs": [],
   "source": [
    "In which of the following situations is it preferable to impute missing feature values with their median value over the mean value?\n",
    "\n",
    "#A. When the features are of the categorical type\n",
    "\n",
    "#B. When the features are of the boolean type\n",
    "\n",
    "C. When the features contain a lot of extreme outliers\n",
    "\n",
    "#D. When the features contain no outliers\n",
    "\n",
    "#E. When the features contain no missing values\n",
    "\n",
    "Answer: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1199c3ab-33f9-4b04-8f00-278e8f8ddfd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data scientist is wanting to explore summary statistics for Spark DataFrame spark_df. The data scientist wants to see the count, mean, standard deviation, minimum, maximum, and interquartile range (IQR) for each numerical feature. Which of the following lines of code can the data scientist run to accomplish the task?\n",
    "\n",
    "A. spark_df.summary ()\n",
    "\n",
    "B. spark_df.stats()\n",
    "\n",
    "C. spark_df.describe().head()\n",
    "\n",
    "#D. spark_df.printSchema()\n",
    "\n",
    "#E. spark_df.toPandas()\n",
    "\n",
    "\n",
    "Answer: A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "560bfd4f-0bc3-48f7-87b1-d7852eb980a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Which of the following tools can be used to distribute large-scale feature engineering without the use of a UDF or pandas Function API for machine learning pipelines?\n",
    "\n",
    "\n",
    "#A. Keras\n",
    "\n",
    "#B. pandas\n",
    "\n",
    "#C. PyTorch\n",
    "\n",
    "D. Spark ML\n",
    "\n",
    "#E. Scikit-learn\n",
    "\n",
    "Answer : D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46854381-fdca-4e7d-9968-aec4fee5f51d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "A data scientist has been given an incomplete notebook from the data engineering team. The notebook uses a Spark DataFrame spark_df on which the data scientist needs to perform further feature engineering. Unfortunately, the data scientist has not yet learned the PySpark DataFrame API. Which of the following blocks of code can the data scientist run to be able to use the pandas API on Spark?\n",
    "\n",
    "A. import pyspark.pandas as ps \n",
    "df = ps.DataFrame(spark_df)\n",
    "\n",
    "#B. import pyspark.pandas as ps \n",
    "df = ps.to_pandas(spark_df)\n",
    "\n",
    "#C. spark_df.to_sql()\n",
    "\n",
    "#D. import pandas as pd \n",
    "df = pd.DataFrame(spark_df)\n",
    "\n",
    "#E. spark_df.to_pandas()\n",
    "\n",
    "Answer:A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebc5c622-33fd-4c1a-b2c0-ef7a8fd7672a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "What is the name of the method that transforms categorical features into a series of binary indicator feature variables?\n",
    "\n",
    "A. Leave-one-out encoding\n",
    "\n",
    "B. Target encoding\n",
    "\n",
    "C. One-hot encoding\n",
    "\n",
    "D. Categorical embeddings\n",
    "\n",
    "E. String indexing\n",
    "\n",
    "Answer: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55958d12-5982-4c6b-802a-bca97bee6150",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Which of the following tools can be used to parallelize the hyperparameter tuning process for single-node machine learning models using a Spark cluster?\n",
    "\n",
    "#A. MLflow Experiment Tracking\n",
    "\n",
    "#B. Spark ML\n",
    "\n",
    "#C. Autoscaling clusters\n",
    "\n",
    "D. Hyperopt\n",
    "\n",
    "#E. Delta Lake\n",
    "\n",
    "Answer: D\n",
    "\n",
    "trails --- SparkTrail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7d3ca66-4ec7-494f-b9ae-51a948bea72c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Q 1-10",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
