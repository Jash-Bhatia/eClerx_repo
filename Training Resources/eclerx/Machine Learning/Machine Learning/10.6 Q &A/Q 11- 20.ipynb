{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94fb414e-d538-423c-8e4d-de0e16143017",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "What best explains how native Spark DataFrames and pandas API on Spark DataFrames are related?\n",
    "\n",
    "A. pandas API on Spark DataFrames are single-node versions of Spark DataFrames with extra metadata.\n",
    "D. pandas API on Spark DataFrames are less flexible versions of Spark DataFrames.\n",
    "C. pandas API on Spark DataFrames consist of Spark DataFrames along with additional metadata.\n",
    "B. pandas API on Spark DataFrames perform better than Spark DataFrames.\n",
    "\n",
    "Answer: C \n",
    "They include extra metadata to track indexing, schema compatibility, and operations mapping between pandas and Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9574f42-7733-49c4-be36-80c702a7c796",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "A data scientist is using MLflow to track their machine learning experiments, including hyperparameter tuning. They want one parent run for the tuning process and a child run for each unique combination of hyperparameter values. All runs are manually started using mlflow.start_run.\n",
    "\n",
    "Which approach can the data scientist use to achieve this MLflow run organization?\n",
    "\n",
    "\n",
    "E. They can specify nested=True when starting the parent run for the tuning process.\n",
    "\n",
    "#A. They can turn on Databricks Autologging.\n",
    "\n",
    "#D. They can start each child run with the same experiment ID as the parent run.\n",
    "\n",
    "B. They can specify nested=True when starting the child run for each unique combination of hyperparameter values.\n",
    "\n",
    "#C. They can start each child run inside the parent run's indented code block using mlflow.start_run().\n",
    "\n",
    "Answer : B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea32d807-e773-465c-998c-a040b1f261bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "with mlflow.start_run() as parent_run:\n",
    "    for param in hyperparameter_combinations:\n",
    "        with mlflow.start_run(nested=True):\n",
    "            train_model(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a88050d-b305-4f7b-aeee-b0059bf9f411",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "A machine learning engineering team manages a Job consisting of three sequential tasks, each executing a separate notebook. Recently, the Job failed during its latest execution.\n",
    "\n",
    "How should the team determine which task caused the failure?\n",
    "\n",
    "#D. Configure each task to run on a dedicated cluster to isolate the problem.\n",
    "\n",
    "B. Check the matrix view in the Job's run history to find the failing task.\n",
    "\n",
    "#A. Execute each notebook interactively to identify any issues.\n",
    "\n",
    "#C. Convert the Job to a Delta Live Tables pipeline for better diagnostics.\n",
    "\n",
    "Anwer: B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f23b3478-37ca-4cec-9bf1-da969bd2fb56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "A data scientist is leveraging Spark SQL to load data into a machine learning pipeline and then uses Spark ML for machine learning tasks.\n",
    "\n",
    "Which compute tool is most appropriate for this scenario?\n",
    "\n",
    "#A. Single Node cluster\n",
    "#C. SQL Warehouse\n",
    "B. Standard cluster\n",
    "#D. None of these compute tools support this task\n",
    "\n",
    "Answer: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6296a60-ded0-4a34-abb8-70aec440b91c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "A machine learning engineer has received a notification that a new Staging version of a model in the MLflow Model Registry has passed all tests. The engineer wants to transition this model to the Production stage.\n",
    "\n",
    "From which Databricks Machine Learning page can this task be completed?\n",
    "\n",
    "#B. The experiment page in the Experiments observatory\n",
    "\n",
    "#D. The model page in the MLflow Model Registry\n",
    "\n",
    "#A. The home page of the MLflow Model Registry\n",
    "\n",
    "C. The model version page in the MLflow Model Registry\n",
    "\n",
    "Answer:C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee0d28e9-5cb9-4c07-a3d6-6621a4aac706",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "When developing a machine learning pipeline using AutoML on Databricks Machine Learning, which of the following steps will the data scientist need to perform outside of their AutoML experiment?\n",
    "\n",
    "\n",
    "C. Model deployment\n",
    "#D. Exploratory data analysis\n",
    "#A. Model tuning\n",
    "#B. Model evaluation\n",
    "\n",
    "Answer: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf27360c-521b-4a3a-94ed-c3ab74f16027",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "A machine learning engineer has identified the best run from an MLflow Experiment, stored the run ID in the variable run_id, and identified the logged model as \"model.\" They want to register this model in the MLflow Model Registry with the name \"best_model.\"\n",
    "\n",
    "Which lines of code can they use to register the model associated with run_id to the MLflow Model Registry?\n",
    "\n",
    "#A. mlflow.register_model(run_id, \"best_model\")\n",
    "\n",
    "B. mlflow.register_model(f\"runs:/{run_id}/model\", \"best_model\")\n",
    "\n",
    "#C. mlflow.register_model(f\"runs:/{run_id}/model\")\n",
    "\n",
    "#D. mlflow.register_model(f\"runs:/{run_id}/best_model\", \"model\")\n",
    "\n",
    "Answer: B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30cf239c-6fe0-425c-82f7-1e5d5d3293a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "A machine learning engineer is frustrated with the need to install the MLflow Python library on every cluster they work with. Seeking a solution, they consult a senior machine learning engineer to find a way to use the MLflow library in their notebooks without having to install it manually each time. The senior engineer advises them to leverage Databricks Runtime for Machine Learning.\n",
    "\n",
    "How can the machine learning engineer start using Databricks Runtime for Machine Learning?\n",
    "\n",
    "C. They can select a Databricks Runtime ML version from the Databricks Runtime Version dropdown during cluster creation.\n",
    "#A. They can modify the init script to enable Databricks Runtime ML when setting up their clusters.\n",
    "#B. They can check the Databricks Runtime ML option while configuring their clusters.\n",
    "#D. They can configure the runtime-version variable in their Spark session to \"ml\".\n",
    "\n",
    "answer: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f64baea-7ca9-41fa-85c8-17c2b902530e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Which of the following machine learning algorithms commonly employs the technique of bagging?\n",
    "\n",
    "A. Gradient boosted trees\n",
    "C. Random forest\n",
    "B. K-means\n",
    "D. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da736576-4534-47b3-bc38-18614fbd0792",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Bagging:Random Forest\n",
    " boosting: gradinet boosting\n",
    "  and \n",
    "  stacking"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Q 11- 20",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
